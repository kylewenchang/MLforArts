## Reading Reflection

### Given that so many of the existing “big data” language models are trained with Western texts and proprietary datasets, what does it even mean to try to decolonize AI?

The fact that so many machine learning models are trained with data that only takes accepted Western culture into account poses an issue in that they would basically ignore/not serve those whose "input data" doesn't look like that, as the model would basically not know how to respond to this foreign-looking data. This issue compounds given the fact that most people doing machine larning (aside from large institutions who go through the process of data collection/labelling) train using public datasets or create models based on other models. I think a lot of this comes from convinience, and the fact that, because of things like colonization, Western texts/culture is the most widespread and easily accessible. Also, 

### How do we get through this whole list of concerns and still build AI that is fun, respectful, tender, pleasurable, kind?

Given all of the ethical conerns of AI/ML, 
